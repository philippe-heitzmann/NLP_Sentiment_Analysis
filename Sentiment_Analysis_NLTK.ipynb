{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1013ad9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#file processing / requests\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import urllib\n",
    "\n",
    "#computer vision\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import PIL\n",
    "\n",
    "#ML \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#display\n",
    "from IPython.display import display\n",
    "from pylab import rcParams\n",
    "\n",
    "#visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import PIL.Image as Image\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a3d738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db2db53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
      "Collecting click\n",
      "  Downloading click-8.0.3-py3-none-any.whl (97 kB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.1.18-cp36-cp36m-win_amd64.whl (272 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\phil0\\anaconda3\\envs\\py36opencv\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\phil0\\anaconda3\\envs\\py36opencv\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\phil0\\anaconda3\\envs\\py36opencv\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\phil0\\anaconda3\\envs\\py36opencv\\lib\\site-packages (from importlib-metadata->click->nltk) (3.10.0.2)\n",
      "Installing collected packages: zipp, importlib-metadata, regex, click, nltk\n",
      "Successfully installed click-8.0.3 importlib-metadata-4.8.3 nltk-3.6.7 regex-2022.1.18 zipp-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb543013",
   "metadata": {},
   "source": [
    "### Notebook Purpose: Implement Sentiment Analysis using nltk package \n",
    "Following https://realpython.com/python-nltk-sentiment-analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba18d6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\phil0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\names.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\phil0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     C:\\Users\\phil0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\state_union.zip.\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\phil0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\twitter_samples.zip.\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\phil0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\movie_reviews.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\phil0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\phil0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\phil0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download([\n",
    "    \"names\",\n",
    "    \"stopwords\",\n",
    "    \"state_union\",\n",
    "    \"twitter_samples\",\n",
    "    \"movie_reviews\",\n",
    "    \"averaged_perceptron_tagger\",\n",
    "    \"vader_lexicon\",\n",
    "    \"punkt\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b78c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = nltk.corpus.movie_reviews.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "673acbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3116bf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['increase', 'principle', 'an', 'the', 'as', 'it', 'to', 'bolster', 'all', 'administration']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(random.sample(words, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6ec6308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 sec to complete <function remove_stopwords at 0x0000019776A9CB70>\n",
      "['work', 'used', 'least', 'government', 'unhesitating', 'complete', 'authorization', 'world', 'free', 'say']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/Administrator/DS/DeepRoad/Object_Detection')\n",
    "sys.path.append('/Users/phil0/DS/DeepRoad/Object_Detection')\n",
    "import utils2\n",
    "from importlib import reload\n",
    "reload(utils2)\n",
    "from utils2 import *\n",
    "\n",
    "words = remove_stopwords(words)\n",
    "print(random.sample(words, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9897791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average item length in words: 6.564070901328431\n"
     ]
    }
   ],
   "source": [
    "answer = 0\n",
    "for item in words:\n",
    "    answer += len(item)\n",
    "print('Average item length in words:', answer / len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "991c827d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PRESIDENT', 'HARRY', 'TRUMAN', 'ADDRESS', 'JOINT']\n"
     ]
    }
   ],
   "source": [
    "print(words[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cb7666e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180589\n"
     ]
    }
   ],
   "source": [
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "100f7de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.4 sec to complete <function tokenize_words at 0x00000197736AFD08>\n",
      "180589\n"
     ]
    }
   ],
   "source": [
    "words2 = tokenize_words(words)\n",
    "print(len(words2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7fd8516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 sec to complete <function tokenize_words at 0x00000197736AFD08>\n",
      "14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('s', 3), (' ', 3), ('i', 2)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words3 = 'This is a test'\n",
    "\n",
    "words4 = tokenize_words(words3)\n",
    "print(len(words4))\n",
    "fd = nltk.FreqDist(words3)\n",
    "fd.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80af11d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1632339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test\n",
      "0.0 sec to complete <function get_freq_dist at 0x00000197748792F0>\n",
      "[('this', 1), ('is', 1), ('a', 1), ('test', 1)]\n",
      "this   is    a test \n",
      "   1    1    1    1 \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(words3)\n",
    "fdist = get_freq_dist(words3)\n",
    "print(fdist.most_common(4))\n",
    "print(fdist.tabulate(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "487db28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 sec to complete <function get_concordances at 0x000001977488F488>\n",
      "[ConcordanceLine(left=['looked', 'forward', 'and', 'moved', 'forward', '.', 'That', 'is', 'what', 'he', 'would', 'want', 'us', 'to', 'do', '.', 'That', 'is', 'what'], query='America', right=['will', 'do', '.', 'So', 'much', 'blood', 'has', 'already', 'been', 'shed', 'for', 'the', 'ideals', 'which', 'we', 'cherish', ',', 'and'], offset=242, left_print=' would want us to do . That is what', right_print='will do . So much blood has already', line=' would want us to do . That is what America will do . So much blood has already'), ConcordanceLine(left=['even', 'a', 'momentary', 'pause', 'in', 'the', 'hard', 'fight', 'for', 'victory', '.', 'Today', ',', 'the', 'entire', 'world', 'is', 'looking', 'to'], query='America', right=['for', 'enlightened', 'leadership', 'to', 'peace', 'and', 'progress', '.', 'Such', 'a', 'leadership', 'requires', 'vision', ',', 'courage', 'and', 'tolerance', '.'], offset=294, left_print='ay , the entire world is looking to', right_print='for enlightened leadership to peace', line='ay , the entire world is looking to America for enlightened leadership to peace'), ConcordanceLine(left=['possible', 'misunderstanding', ',', 'both', 'Germany', 'and', 'Japan', 'can', 'be', 'certain', ',', 'beyond', 'any', 'shadow', 'of', 'a', 'doubt', ',', 'that'], query='America', right=['will', 'continue', 'the', 'fight', 'for', 'freedom', 'until', 'no', 'vestige', 'of', 'resistance', 'remains', '!', 'We', 'are', 'deeply', 'conscious', 'of'], offset=433, left_print='beyond any shadow of a doubt , that', right_print='will continue the fight for freedom', line='beyond any shadow of a doubt , that America will continue the fight for freedom')]\n"
     ]
    }
   ],
   "source": [
    "import utils2\n",
    "from importlib import reload\n",
    "reload(utils2)\n",
    "from utils2 import *\n",
    "\n",
    "concordance_list= get_concordances(corpus = nltk.corpus.state_union.words(), target_word = 'america', n_lines= 3)\n",
    "print(concordance_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd1851af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PRESIDENT', 'HARRY', 'S', 'TRUMAN', 'S']\n",
      "0.3 sec to complete <function remove_stopwords at 0x0000019776A9CB70>\n",
      "['PRESIDENT', 'HARRY', 'TRUMAN', 'ADDRESS', 'JOINT']\n",
      "['president', 'harry', 'truman', 'address', 'joint']\n"
     ]
    }
   ],
   "source": [
    "state_union = [w for w in nltk.corpus.state_union.words() if w.isalpha()]\n",
    "print(state_union[:5])\n",
    "state_union = remove_stopwords(state_union)\n",
    "print(state_union[:5])\n",
    "state_union = [word.lower() for word in state_union]\n",
    "print(state_union[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "40c51edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 sec to complete <function get_collocations at 0x000001977488F048>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('address', 'joint', 'session', 'congress'), 33),\n",
       " (('congress', 'state', 'union', 'january'), 30),\n",
       " (('state', 'union', 'january', 'mr'), 28)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grams = get_collocations(gramtype = 'quadgram', words = state_union)\n",
    "grams.ngram_fd.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ea4f393a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 sec to complete <function get_vader_polarity_score at 0x0000019779CCA400>\n",
      "{'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'compound': 0.6249}\n"
     ]
    }
   ],
   "source": [
    "vader_scores = get_vader_polarity_score('\"Wow, this is awesome\"')\n",
    "print(vader_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f11ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
